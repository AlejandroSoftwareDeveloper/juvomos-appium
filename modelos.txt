â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
           GUÃA COMPLETA DE MODELOS OLLAMA 2025
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ§  MODELOS DE PROPÃ“SITO GENERAL
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Llama 3 / 3.1 / 3.3 (Meta)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Variantes: 1B, 3B, 8B, 70B, 405B
Uso: Tareas generales, chatbots, anÃ¡lisis de documentos largos (hasta 128K tokens de contexto), asistentes virtuales
Destacado: Excelente equilibrio entre calidad y eficiencia. El 70B rivaliza con GPT-4 en muchas tareas

Mistral 7B
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Uso: Tareas diarias rÃ¡pidas, resumen de textos, redacciÃ³n de correos, integraciÃ³n en herramientas empresariales
Ventaja: Muy rÃ¡pido y preciso, ideal para hardware modesto

Qwen 2.5 (Alibaba)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Variantes: 0.5B a 72B
Uso: Aplicaciones multilingÃ¼es (soporta 29+ idiomas), razonamiento matemÃ¡tico, tareas de agentes autÃ³nomos
Especialidad: Rendimiento excepcional en espaÃ±ol y otros idiomas no ingleses

DeepSeek-V2/V3
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Variantes: V2, V2.5 disponibles en Ollama
Uso: Procesamiento de lenguaje a gran escala, arquitectura Mixture-of-Experts (MoE) eficiente
Contexto: Hasta 128K tokens

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’» MODELOS ESPECIALIZADOS EN CÃ“DIGO
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

DeepSeek-R1 Series
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Variantes: 1.5B, 8B, 14B, 32B, 70B
Uso: Razonamiento avanzado, resoluciÃ³n de problemas algorÃ­tmicos complejos, diseÃ±o de sistemas, debugging
Destacado: Rendimiento cercano a GPT-4 en razonamiento lÃ³gico

CodeLlama (Meta)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Variantes: 7B, 13B, 34B
Uso: GeneraciÃ³n y comprensiÃ³n de cÃ³digo en 20+ lenguajes de programaciÃ³n, debugging complejo, autocompletado
Especialidad: Optimizado especÃ­ficamente para tareas de desarrollo

Qwen2.5-Coder
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Variantes: 1.5B, 7B, 14B, 32B
Uso: Manejo de grandes bases de cÃ³digo, contextos largos, tareas de agentes de programaciÃ³n
Ventaja: Excelente para proyectos con extensas bases de cÃ³digo

DeepSeek-Coder V2
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Uso: ComprensiÃ³n avanzada de cÃ³digo, soporta 87 lenguajes, entrenado en 2 billones de tokens
Especialidad: Cambios de cÃ³digo entre archivos (cross-file)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ–¼ï¸ MODELOS MULTIMODALES (VISIÃ“N + TEXTO)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Llama 3.2 Vision
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Variantes: 11B, 90B
Uso: AnÃ¡lisis de imÃ¡genes, descripciÃ³n visual, conversiÃ³n de diagramas a cÃ³digo, interfaces visuales
TamaÃ±o: 7.9GB (11B) y 55GB (90B)

LLaVA 1.6 (Large Language and Vision Assistant)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Variantes: 7B, 13B, 34B
Uso: Preguntas y respuestas visuales, anÃ¡lisis de arquitecturas de red, descripciÃ³n de imÃ¡genes tÃ©cnicas
API: Soporta imÃ¡genes en base64 para anÃ¡lisis

Qwen2-VL / Qwen3-VL
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Uso: ComprensiÃ³n avanzada de visiÃ³n-lenguaje, desarrollo UI/UX, conversiÃ³n de diseÃ±os a cÃ³digo, debugging visual
Destacado: El modelo de visiÃ³n mÃ¡s potente de la familia Qwen

Moondream 2
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ParÃ¡metros: 1.4B
TamaÃ±o: Solo 829MB
Uso: AnÃ¡lisis visual ligero, ideal para dispositivos con recursos limitados

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš¡ MODELOS LIGEROS Y EDGE COMPUTING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Phi-4 (Microsoft)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Variantes: 14B
Uso: Despliegue en edge, dispositivos mÃ³viles, Raspberry Pi, aplicaciones offline
Rendimiento: Rivaliza con modelos mucho mÃ¡s grandes en benchmarks acadÃ©micos

Phi-3 Mini/Medium
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Variantes: 3.8B (Mini), 14B (Medium)
Uso: EjecuciÃ³n en telÃ©fonos mÃ³viles, asesoramiento agrÃ­cola en campo sin internet, IoT
Ventaja: Funciona en hardware mÃ­nimo, ideal para Ã¡reas remotas

TinyLlama
â”€â”€â”€â”€â”€â”€â”€â”€â”€
ParÃ¡metros: 1.1B
TamaÃ±o: Extremadamente ligero
Uso: Prototipado rÃ¡pido, dispositivos IoT, respuestas instantÃ¡neas, laptops antiguas
Carga: Se carga en segundos

Gemma 2 (Google)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Variantes: 2B, 9B, 27B
Uso: Tareas conversacionales, dispositivos pequeÃ±os (2B), balance rendimiento/tamaÃ±o (9B), alto rendimiento (27B)
OptimizaciÃ³n: Flash Attention activado por defecto en Ollama

Llama 3.2 (1B/3B)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Uso: Tareas ligeras en dispositivos mÃ³viles, respuestas rÃ¡pidas, bajo consumo de memoria

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸŒ MODELOS MULTILINGÃœES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Aya
â”€â”€â”€
Uso: Soporta 100+ idiomas, incluyendo lenguas menos comunes
Especialidad: TraducciÃ³n natural sin frases forzadas, guÃ­as comunitarias multilingÃ¼es

Command-R
â”€â”€â”€â”€â”€â”€â”€â”€â”€
Uso: Documentos largos multilingÃ¼es, manejo de contexto extenso en mÃºltiples idiomas

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ­ MODELOS ESPECIALIZADOS EN CONVERSACIÃ“N
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Vicuna
â”€â”€â”€â”€â”€â”€
Variantes: 7B, 13B
Uso: Chatbots conversacionales naturales, asistentes personalizados, interacciones largas
CaracterÃ­stica: Respuestas fluidas, no robÃ³ticas

Neural Chat 7B
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Uso: ExplicaciÃ³n de conceptos complejos en tÃ©rminos simples, guÃ­as de usuario, comunicaciÃ³n con no expertos

Starling 7B
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Uso: Seguimiento preciso de instrucciones, flujos de trabajo paso a paso, listas de verificaciÃ³n de proyectos

Orca Mini
â”€â”€â”€â”€â”€â”€â”€â”€â”€
Variantes: 3B, 7B, 13B
Uso: Eficiencia en hardware antiguo, generaciÃ³n de lecciones educativas, consultas bÃ¡sicas

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”“ MODELOS SIN CENSURA (UNCENSORED)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Dolphin
â”€â”€â”€â”€â”€â”€â”€
Variantes: 7B, 70B
Uso: Trabajo creativo abierto, escritura de ficciÃ³n, brainstorming sin restricciones
Nota: Requiere verificaciÃ³n de salidas

Llama 2 Uncensored
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Uso: InvestigaciÃ³n, tareas creativas sin filtros de seguridad

WizardLM
â”€â”€â”€â”€â”€â”€â”€â”€
Uso: ExploraciÃ³n de ideas abiertas, creatividad sin restricciones

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”§ OTROS MODELOS NOTABLES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Solar 10.7B
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Uso: Rendimiento equilibrado en mÃºltiples tareas, alternativa a Mistral

GPT-OSS (OpenAI)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Uso: Razonamiento potente, tareas de agentes, casos de uso versÃ¡tiles para desarrolladores
Nota: Modelos de peso abierto de OpenAI

GLM-4.6
â”€â”€â”€â”€â”€â”€â”€
Uso: Capacidades agenticas avanzadas, generaciÃ³n de cÃ³digo, refactoring, tareas de desarrollo autÃ³nomo

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ GUÃA DE SELECCIÃ“N POR HARDWARE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

8GB RAM / CPU bÃ¡sico:
â€¢ TinyLlama
â€¢ Phi-3 Mini
â€¢ Gemma 2B
â€¢ Orca Mini 3B

16GB RAM / GPU entry-level:
â€¢ Mistral 7B
â€¢ Llama 3.1 8B
â€¢ Qwen2.5 7B
â€¢ Gemma 9B

32GB RAM / GPU mid-range:
â€¢ Llama 3.1 70B (cuantizado)
â€¢ Qwen2.5 14B
â€¢ DeepSeek-R1 14B

64GB+ RAM / GPU high-end:
â€¢ Llama 3.3 70B
â€¢ DeepSeek-R1 32B/70B
â€¢ Qwen2.5 72B

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ COMANDOS BÃSICOS DE OLLAMA
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Descargar un modelo:
    ollama pull llama3.3:70b

Ejecutar modelo interactivo:
    ollama run deepseek-r1:8b

Listar modelos instalados:
    ollama list

Eliminar modelo:
    ollama rm mistral:latest

Ver informaciÃ³n del modelo:
    ollama show qwen2.5:32b

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… VERIFICACIÃ“N DE INSTALACIÃ“N
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Verificar versiÃ³n:
    ollama --version

Verificar que el servidor estÃ¡ corriendo:
    curl http://localhost:11434/api/tags

Ver ruta de instalaciÃ³n:
    which ollama

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Biblioteca completa: https://ollama.com/library
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
